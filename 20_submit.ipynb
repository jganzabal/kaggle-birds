{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_FOLDER = Path('/Users/julian/Downloads/birds/birdsong-recognition/')\n",
    "\n",
    "KAGGLE_MODEL_FOLDER = Path('../input/birdscall-model/')\n",
    "MODEL_FOLDER = KAGGLE_MODEL_FOLDER if os.path.exists(KAGGLE_MODEL_FOLDER) else Path('./models')\n",
    "\n",
    "\n",
    "TEST_PATH = Path('../input/birdsong-recognition') if os.path.exists('../input/birdsong-recognition/test_audio') else Path('./test_check/')\n",
    "TEST_AUDIO_PATH = TEST_PATH/'test_audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_check/test_audio models test_check\n"
     ]
    }
   ],
   "source": [
    "print(TEST_AUDIO_PATH, MODEL_FOLDER, TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(TEST_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>row_id</th>\n",
       "      <th>seconds</th>\n",
       "      <th>audio_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>site_3</td>\n",
       "      <td>site_3_9cc5d9646f344f1bbb52640a988fe902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9cc5d9646f344f1bbb52640a988fe902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>site_3</td>\n",
       "      <td>site_3_a56e20a518684688a9952add8a9d5213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a56e20a518684688a9952add8a9d5213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>site_3</td>\n",
       "      <td>site_3_96779836288745728306903d54e264dd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96779836288745728306903d54e264dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>site_3</td>\n",
       "      <td>site_3_f77783ba4c6641bc918b034a18c23e53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f77783ba4c6641bc918b034a18c23e53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>site_3</td>\n",
       "      <td>site_3_856b194b097441958697c2bcd1f63982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>856b194b097441958697c2bcd1f63982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      site                                   row_id  seconds  \\\n",
       "71  site_3  site_3_9cc5d9646f344f1bbb52640a988fe902      NaN   \n",
       "72  site_3  site_3_a56e20a518684688a9952add8a9d5213      NaN   \n",
       "73  site_3  site_3_96779836288745728306903d54e264dd      NaN   \n",
       "74  site_3  site_3_f77783ba4c6641bc918b034a18c23e53      NaN   \n",
       "75  site_3  site_3_856b194b097441958697c2bcd1f63982      NaN   \n",
       "\n",
       "                            audio_id  \n",
       "71  9cc5d9646f344f1bbb52640a988fe902  \n",
       "72  a56e20a518684688a9952add8a9d5213  \n",
       "73  96779836288745728306903d54e264dd  \n",
       "74  f77783ba4c6641bc918b034a18c23e53  \n",
       "75  856b194b097441958697c2bcd1f63982  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['site']=='site_3'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pytorch_model_all_conv(window_size=1024, resnet='resnet18', pretrained=True, n_classes=10, init_fourier=False, train_fourier=False):\n",
    "    kernel_size = window_size\n",
    "    stride = kernel_size//4\n",
    "    filters = kernel_size//2\n",
    "    \n",
    "    model_resnet = torch.hub.load('pytorch/vision:v0.6.0', resnet, pretrained=pretrained)\n",
    "    if resnet=='resnet18':\n",
    "        linear_inp = 512\n",
    "    else:\n",
    "        linear_inp = 2048\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.cos = nn.Conv1d(1, filters, kernel_size, stride=stride)\n",
    "            self.sin = nn.Conv1d(1, filters, kernel_size, stride=stride)\n",
    "            if init_fourier:\n",
    "                cos_weights, sin_weights = get_fourier_weights(window_size)\n",
    "                self.cos.weight.data = torch.from_numpy(cos_weights.reshape(cos_weights.shape[0], 1, cos_weights.shape[1])).float()\n",
    "                self.sin.weight.data = torch.from_numpy(sin_weights.reshape(sin_weights.shape[0], 1, sin_weights.shape[1])).float()\n",
    "            self.resnet = nn.Sequential(*list(model_resnet.children())[:-1])\n",
    "            self.conv_out = nn.Conv2d(linear_inp, n_classes, 1)\n",
    "        def forward(self, x):\n",
    "            min_power=1e-10\n",
    "            x_spec = 10*torch.log10(self.cos(x)**2 + self.sin(x)**2 + min_power)\n",
    "            x_spec = (x_spec + 60)/120\n",
    "            x = torch.reshape(x_spec, (len(x_spec), 1, 512, -1))\n",
    "            x = torch.cat([x, x, x], dim=1)\n",
    "            x = self.resnet(x)\n",
    "            x = self.conv_out(x).flatten(start_dim=1)\n",
    "            return x_spec, x\n",
    "    model = Net()\n",
    "    if not train_fourier:\n",
    "        list(model.cos.parameters())[0].requires_grad = False\n",
    "        list(model.sin.parameters())[0].requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/julian/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024\n",
    "n_classes = 264\n",
    "model = get_pytorch_model_all_conv(window_size, resnet='resnet18', \n",
    "                                   pretrained=False, n_classes=n_classes, \n",
    "                                   init_fourier=False, train_fourier=False).to(device)\n",
    "state_dict = torch.load(MODEL_FOLDER/f'model_ambient_{n_classes}_0.627.pth', map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.load(MODEL_FOLDER/f'classes_{n_classes}.npy')\n",
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, items, classes, rec):\n",
    "        self.items = items\n",
    "        self.vocab = classes\n",
    "        self.mean = rec.mean()\n",
    "        self.std = rec.std()\n",
    "        self.rec = rec\n",
    "    def __getitem__(self, idx):\n",
    "        _, rec_fn, start = self.items[idx]\n",
    "        x = self.rec[start*SAMPLE_RATE:(start+5)*SAMPLE_RATE]\n",
    "        x = self.normalize(x)\n",
    "        return x.astype(np.float32)\n",
    "    def normalize(self, x):\n",
    "        return (x - self.mean) / self.std    \n",
    "    def __len__(self):\n",
    "        return len(self.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "duration = 5\n",
    "res_type = 'kaiser_best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(preds):\n",
    "    all_preds = []\n",
    "    for row in preds:\n",
    "        row_birds = classes[np.where(row>0)]\n",
    "        if len(row_birds) == 0:\n",
    "            row_birds = ['nocall']\n",
    "        all_preds = all_preds + [' '.join(row_birds)]\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sites_1_2():\n",
    "    row_ids = []\n",
    "    results = []\n",
    "    total_seconds = 0\n",
    "    for audio_id in test_df[test_df.site.isin(['site_1', 'site_2'])].audio_id.unique():\n",
    "        items = [(row.row_id, row.audio_id, int(row.seconds)-5) for idx, row in test_df[test_df.audio_id == audio_id].iterrows()]\n",
    "        # Load full audio archive\n",
    "        rec = librosa.load(TEST_AUDIO_PATH/f'{audio_id}.mp3', sr=SAMPLE_RATE, res_type=res_type)[0]\n",
    "        test_ds = AudioDataset(items, classes, rec)\n",
    "        dl = DataLoader(test_ds, batch_size=128)\n",
    "        for batch in dl:\n",
    "            with torch.no_grad():\n",
    "                total_seconds = total_seconds + duration*len(items)\n",
    "                _, preds = model(batch.reshape(-1, 1, SAMPLE_RATE*duration).to(device))\n",
    "                preds = preds.cpu().detach()\n",
    "                birds = get_classes(preds)\n",
    "            results = results + birds\n",
    "        row_ids += [item[0] for item in items]\n",
    "    return row_ids, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 2.02 s, total: 29 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "row_ids_12, results_12 = predict_sites_1_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_site_3():\n",
    "    row_ids = []\n",
    "    results = []\n",
    "    for audio_id in test_df[test_df.site.isin(['site_3'])].audio_id.unique():\n",
    "        row_id = test_df[test_df.audio_id == audio_id]['row_id'].values[0]\n",
    "        row_ids.append(row_id)\n",
    "        rec = librosa.load(TEST_AUDIO_PATH/f'{audio_id}.mp3', sr=SAMPLE_RATE, res_type=res_type)[0]\n",
    "        rec = (rec - rec.mean())/rec.std()\n",
    "        chunks = len(rec)//(SAMPLE_RATE*duration)\n",
    "        if chunks == 0:\n",
    "            reshaped_rec = rec\n",
    "        else:\n",
    "            reshaped_rec = rec[:chunks*SAMPLE_RATE*duration].reshape(-1, SAMPLE_RATE*duration)\n",
    "        _, preds = model(torch.from_numpy(reshaped_rec.reshape(-1, 1, SAMPLE_RATE*duration)).to(device))\n",
    "        preds = preds.cpu().detach()\n",
    "        predicted_classes = get_classes(preds)\n",
    "        joined_predicted_classes = []\n",
    "        for pr_cl in predicted_classes:\n",
    "            joined_predicted_classes = joined_predicted_classes + pr_cl.split(' ')\n",
    "        predicted_classes = list(np.unique(joined_predicted_classes))\n",
    "#         print(predicted_classes)\n",
    "        if ('nocall' in predicted_classes) and (len(predicted_classes)>1):\n",
    "            predicted_classes.remove('nocall')\n",
    "#         print(predicted_classes)\n",
    "        birds = ' '.join(predicted_classes)\n",
    "        results.append(birds)\n",
    "#         break\n",
    "    return row_ids, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/opt/anaconda3/envs/deep/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 3.16 s, total: 28.8 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "row_ids_3, results_3 = predict_site_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids = row_ids_12 + row_ids_3\n",
    "results = results_12 + results_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(data={'row_id': row_ids, 'birds': results})\n",
    "\n",
    "sub = pd.DataFrame(data={'row_id': test_df.row_id})\n",
    "sub = sub.merge(predicted, 'left', 'row_id')\n",
    "sub.fillna('nocall', inplace=True)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_15</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_25</td>\n",
       "      <td>aldfly hamfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>site_3_9cc5d9646f344f1bbb52640a988fe902</td>\n",
       "      <td>aldfly comyel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>site_3_a56e20a518684688a9952add8a9d5213</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>site_3_96779836288745728306903d54e264dd</td>\n",
       "      <td>aldfly hamfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>site_3_f77783ba4c6641bc918b034a18c23e53</td>\n",
       "      <td>yebfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>site_3_856b194b097441958697c2bcd1f63982</td>\n",
       "      <td>aldfly hamfly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        row_id          birds\n",
       "0    site_1_41e6fe6504a34bf6846938ba78d13df1_5         aldfly\n",
       "1   site_1_41e6fe6504a34bf6846938ba78d13df1_10         aldfly\n",
       "2   site_1_41e6fe6504a34bf6846938ba78d13df1_15         aldfly\n",
       "3   site_1_41e6fe6504a34bf6846938ba78d13df1_20         nocall\n",
       "4   site_1_41e6fe6504a34bf6846938ba78d13df1_25  aldfly hamfly\n",
       "..                                         ...            ...\n",
       "71     site_3_9cc5d9646f344f1bbb52640a988fe902  aldfly comyel\n",
       "72     site_3_a56e20a518684688a9952add8a9d5213         aldfly\n",
       "73     site_3_96779836288745728306903d54e264dd  aldfly hamfly\n",
       "74     site_3_f77783ba4c6641bc918b034a18c23e53         yebfly\n",
       "75     site_3_856b194b097441958697c2bcd1f63982  aldfly hamfly\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/julian/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "model_resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_resnet, 'resnet18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('resnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
